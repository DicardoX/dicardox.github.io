---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I'm Chunyu Xue, a fourth-year Direct PhD Candidate in [Emerging Parallel Computing Center (EPCC)](http://epcc.sjtu.edu.cn) from [Shanghai Jiao Tong University (SJTU)](https://www.sjtu.edu.cn), advised by [Prof. Quan Chen](https://www.cs.sjtu.edu.cn/~chen-quan/index_EN.html). My research interests lie in building efficient and scalable systems for LLM and MultiModal training, fine-tuning, and cluster-level scheduling. 
Currently, I'm working as a research intern in [ByteDance Seed](https://seed.bytedance.com/en/) (Training Infrastructure). I worked as an engineering intern in Microsoft Cloud+AI. I received my B.S. in Computer Science and Technology from SJTU.
Feel free to reach out if you are interested in potential collaboration!


# Education

 - *2022.09 - Now*, Shanghai Jiao Tong University `Ph.D. in Computer Science`
 - *2018.09 - 2022.06*, Shanghai Jiao Tong University `B.S. in Computer Science`


# Experiences

 - *2025.03 - Now*, ByteDance Seed (Training Infrastructure) `Research Intern`
 - *2021.06 - 2021.09*, Microsoft (Cloud+AI) `Software Engineer Intern`


# Publications 

## Published

 - <span style="background-color: #B16A6F; color: white; padding: 2px 6px; border-radius: 3px; font-weight: bold; font-size: 0.9em;">EuroSys 2026</span> **Chunyu Xue**, Weihao Cui, Quan Chen, Chen Chen, Han Zhao, Shulai Zhang, Linmei Wang, Yan Li, Limin Xiao, WeiFeng Zhang, Jing Yang, Bingsheng He, Minyi Guo. "Arena: Efficiently Training Large Models via Dynamic Scheduling and Adaptive Parallelism Co-Design".

 - <span style="background-color: #B16A6F; color: white; padding: 2px 6px; border-radius: 3px; font-weight: bold; font-size: 0.9em;">EuroSys 2026</span> **Chunyu Xue**, Yangrui Chen, Jianyu Jiang, Ningxin Zheng, Junda Feng, Jingji Chen, Shixiong Zhao, Shen Yan, Yi Lin, Lei Shi, Zanbo Wang, Lishu Luo, Faming Wu, Haibin Lin, Yanghua Peng, Xin Liu, Quan Chen. "MegaScale-Omni: A Hyper-Scale, Workload-Resilient System for MultiModal LLM Training in Production".

 - <span style="background-color: #B16A6F; color: white; padding: 2px 6px; border-radius: 3px; font-weight: bold; font-size: 0.9em;">NSDI 2026</span> **Chunyu Xue**, Yi Pan, Weihao Cui, Quan Chen, Shulai Zhang, Bingsheng He, Minyi Guo. "MuxTune: Efficient Multi-Task LLM Fine-Tuning in Multi-Tenant Datacenters via Spatial-Temporal Backbone Multiplexing".

 - <span style="background-color: #B16A6F; color: white; padding: 2px 6px; border-radius: 3px; font-weight: bold; font-size: 0.9em;">EuroSys 2026</span> Yuxuan Wang, Yanbo Wang, Chen Chen, **Chunyu Xue**, Qizhen Weng, Yin Chen, Zeren Li, Xuqi Zhu, Yongqiang Yang, Quan Chen, Minyi Guo. "Suika: Efficient and High-quality Re-scheduling of 3D-parallelized LLM Training Jobs in Shared Clusters".

 - <span style="background-color: #B16A6F; color: white; padding: 2px 6px; border-radius: 3px; font-weight: bold; font-size: 0.9em;">EuroSys 2025</span> Shulai Zhang, Quan Chen, Weihao Cui, Han Zhao, **Chunyu Xue**, Zhen Zheng, Wei Lin, Minyi Guo. "Improving GPU Sharing Performance through Adaptive Bubbleless Spatial-Temporal Sharing".

 - <span style="background-color: #B16A6F; color: white; padding: 2px 6px; border-radius: 3px; font-weight: bold; font-size: 0.9em;">TACO 2025</span> Pengyu Yang, Weihao Cui, **Chunyu Xue**, Han Zhao, Chen Chen, Quan Chen, Jing Yang, Minyi Guo. "Taming Flexible Job Packing in Deep Learning Training Clusters".

## Preprint





